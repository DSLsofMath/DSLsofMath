* DSLsofMath Week 7: Linear Algebra and the Laplace transform
+ Mix of Chapter 7 and Chapter 8 (to get started early on the Laplace
  transform).
** Lecture 7.1: Linear Algebra 1
+ The DSL of the this lecture describes
  vectors, linear transforms, matrices
*** L7.1a https://jamboard.google.com/d/1uov9xi_I5D27_hoXTDbWo5sPcEg3UHP0yx40xIqLshE/viewer
+ class (Field s, AddGroup v) => VectorSpace v s where
    scale :: s -> v -> v  -- s for "scalars", v for "vectors"
+ Laws: {- very compact: add types, expand -}
  ∀ c. GroupHom(scale c, (addV,zeroV,negateV), (addV,zeroV,negateV))
       GroupHom(scale,   (addS,zeroS,negateS), (addF,zeroF,negateF))
      MonoidHom(scale,   (mulS,oneS)         , ((.), id))
+ Laws expanded one step + with types
  scale c :: v->v;
  addV :: v->v->v; zeroV :: v; negateV :: v->v
  ∀ c. H2(scale c, addV,    addV   )  &&
       H0(scale c, zeroV,   zeroV  )  &&
	 H1(scale c, negateV, negateV)

  scale :: s -> (v->v)
  addS :: s->s->s;                zeroS :: s;      negateS :: s->s
  addF :: (v->v)->(v->v)->(v->v); zeroF :: (v->v); negateF :: (v->v)->(v->v)
       H2(scale, addS,    addF   ) &&
	 H0(scale, zeroS,   zeroF  ) &&
	 H1(scale, negateS, negateF)

  scale :: s -> (v->v)
  mulS :: s->s->s;                oneS :: s
  (.)  :: (v->v)->(v->v)->(v->v); id :: (v->v)
       H2(scale, mulS, (.)) &&
       H0(scale, oneS, id)
+ Laws expanded two steps: (types unchanged)
  ∀ c. (∀ v₁, v₂. scale c (addV v₁ v₂) = addV (scale c v₁) (scale c v₂)) &&
       (scale c zeroV = zeroV) &&
	 (∀ v. scale c (negateV v) = negateV (scale c v))

       (∀ s₁, s₂. scale (addS s₁ s₂) = addF (scale s₁) (scale s₂)) &&
	 (scale zeroS = zeroF) &&
	 (∀ s. scale (negateS s) = negateF (scale s))

       (∀ s₁, s₂. scale (mulS s₁ s₂) = scale s₁ . scale s₂) &&
       (scale oneS = id)
+ Laws expanded three steps: (first group unchanged)
  ∀ c. (∀ v₁, v₂. scale c (addV v₁ v₂) = addV (scale c v₁) (scale c v₂)) &&
       (scale c zeroV = zeroV) &&
	 (∀ v. scale c (negateV v) = negateV (scale c v))

       (∀ s₁, s₂, v. scale (addS s₁ s₂) v = addV (scale s₁ v) (scale s₂ v)) &&
	 (∀ v. scale zeroS v = zeroV) &&
	 (∀ s, v. scale (negateS s) v = negateV (scale s v))

       (∀ s₁, s₂, v. scale (mulS s₁ s₂) v = scale s₁ (scale s₂ v)) &&
       (∀ v. scale oneS v = v)
+ Laws with (overloaded) operators, 0, and 1:
    ∀ c. (∀ v₁, v₂. c ◃ (v₁+v₂) = (c◃v₁) + (c◃v₂)) &&
         (c◃0 = 0) &&
	 (∀ v. c◃(-v) = -(c◃v))

    ∀ v. (∀ s₁, s₂. (s₁+s₂)◃v = (s₁◃v)+(s₂◃v)) &&
	 (0◃v = 0) &&
	 (∀ s. (-s)◃v = -(s◃v))

    ∀ v. (∀ s₁, s₂. (s₁·s₂)◃v = s₁◃(s₂◃v)) &&
         (1◃v = v)
+ instance Field s => VectorSpace s s where scale = (*)
  + here |s = v|, so |scale : s->v->v| becomes |scale : s->s->s|
  + we can see the scalars as a "1-dimensional vector space" with canonical basis one
    + scale s one = s*one = s
+ A two-dimensional example: file:XYPlaneExampleVectors.png
  data Axes   = X | Y
  type XYVec  = Axes -> REAL
  + Example vectors:
    v₁ X = TODO; v₁ Y = TODO;
    v₂ X = TODO; v₂ Y = TODO;
    v₃ X = TODO; v₃ Y = TODO;
  + instance VectorSpace XYVec REAL where scale = scaleF
    scaleF :: REAL -> (Axes -> REAL) -> (Axes -> REAL)
    scaleF c v = \g -> c * v g
+ Linear Combinations
  -- Math notation: Σᵢ aᵢ◃vᵢ = Σᵢ (scale aᵢ vᵢ)
  linComb :: (Finite g, VectorSpace v s) => (g->s) -> (g->v) -> v
  linComb a v = sum (map (\i->scale (a i) (v i) finiteDomain)
+ Linearly independent, span, and basis:
  + A collection of vectors v₀, ..., vₙ is *linearly independent* iff
    ∀ a:{0..n}->s. (linComb a v == 0) ⇔ (∀ i. aᵢ==0)
  + The span S of a collection of vectors V (over a field S) is the
    set of all linear combinations of those vectors.
  + A basis B for a vector space V over a field S is a linearly
    independent collection of vectors which spans V.
+ Example (canonical) basis: for
  + let G = {0..n}; V = G->s; e : G -> V;
        eᵢ j = if i==j then 1 else 0
  + Then e is a basis for V
+ Next up: linear transformation (homomorphism between vector spaces)
*** L7.1b https://jamboard.google.com/d/1Kx-uI4J8zi4GejuNuSP-SxxydeqgHguychnbvpUiCxM/viewer
+ h : U -> V   where U and V and vector spaces over the same scalars s
+ LinTran(h,U,V) =    H₀(h,zeroᵤ,zeroᵥ)
                 ∧   H₂(h,(+ᵤ),(+ᵥ))
		 ∧∀c.H₁(h,scaleᵤ c,scaleᵥ c)
+ Examples:   ∀c. LinTran(scaleᵥ c, V, V)
              ∀i. LinTran(apply i, g->s, s)  -- "projections"
+ Linear transformations between U = G -> s and V = G' -> s
  h v = *TODO* (or see calculation below)
  + Calculation
    h v
      = -- e is the canonical basis => v = Σᵁᵢ (scaleᵁ vᵢ eᵢ)
    h (Σᵁᵢ (scaleᵁ vᵢ eᵢ))
      = -- h distributes over Σ - note the change of type
    Σⱽᵢ (h (scaleᵁ vᵢ eᵢ))
      = -- h distributes over scale - note the change of type (again)
    Σⱽᵢ (scaleⱽ vᵢ (h eᵢ))
      = -- Def. of linComb
   linComb v (h ∘ e)
  + Note: to compute h v for any (infinitely many) v it is enough to
    store the results of h eᵢ for every i (finitely many). Each h eᵢ
    is a vector in V, thus we can store this collection in a table,
    usually called a *matrix*.
    file:Matrix_shape.png
      |     |      |     |     |
      |     |      |     |     |
      | h eₒ | h e₁ | ... | h eₙ |
      |     |      |     |     |
      |     |      |     |     |
  + This matrix is the "syntax" of a linear transformation and the
    linear function h : U -> V is the semantics.
  + evalMV m v = linComb v m
+ Example: der : P₃ -> P₂ as a linear transformation
  Def. Pₙ = { polynomials of degree ≤ n} = {0..n} -> REAL
    -- represented as coefficients
  evalₚ : Pₙ -> (REAL -> REAL)
  evalₚ a = Σᵢ scale aᵢ pᵢ
  Basis:
    p : {0..n} -> REAL -> REAL
    p i x = xⁱ
+ Example cont.: the matrix version DER of der
  + Step 1: type / dimensions of the target
    each column of the matrix represents a vector in the target space
    thus, here a polynomial in P₂
    represented by three coefficients: (think of a₀ + a₁*x + a₂*x²)
    thus we need three rows
  + Step 2: type / dimensions of the source
    there is one column for each basis vector in the source space
    thus, one for each of 1, x, x², x³
    thus we need four columns
  + file:DER3_shape.png
          | 0 | 1 | 0 | 0 |
    DER = | 0 | 0 | 2 | 0 |
          | 0 | 0 | 0 | 3 |
  + Step 3: fill in the resulting shape with the
    der (p i) = scale i (p (i-1))
          | 0 | 1 | 0 | 0 |
    DER = | 0 | 0 | 2 | 0 |
          | 0 | 0 | 0 | 3 |
+ Composing homomorphisms (here LinTran)
  + Typing: let A, B, C be vector spaces and hᵢ linear transformations
	 h₂      h₁
     C <———— B <———— A
	    h₂∘h₁
     C <———————————— A

  + Property: "homomorphisms compose"
     LinTran(h₁,   A,B) ∧
     LinTran(h₂,     B,C) ⇒
     LinTran(h₂∘h₁,A,  C)

+ Composing LinTran (towards matrix multiplication)
  + Typing + specification: let hᵢ = evalMV Mᵢ
	 h₂      h₁
     C <———— B <———— A
         M₂      M₁

	    h₂∘h₁
     C <———————————— A
         mulM M₂ M₁

  + Property? (three variants)
     ∃ mulM . evalMV (mulM M₂ M₁) = evalMV M₂ ∘ evalMV M₁
     "can we compute a matrix for the composition h₂ ∘ h₁ from just M₂ and M₁?"
     ∃ mulM . H2(evalMV, mulM, (∘))
+ Example:
  A = a->REAL; B=b->REAL; C=c->REAL
  a={U,V}; b={0,1,2}; c={1}
       |      |      |      | 1 | 0 |
  M₁ = |h₁ eᵤ | h₁ eᵥ |  =   | 1 | 1 |
       |      |      |      | 0 | 1 |

  M₂ = | 0 | 2 | 0 |
  h₂ w = \i -> scale 2 (w i)   -- scaled projection

  mulM M₂ M₁ = | 2 | 2 |
+ Helper functions for vectors and matrices
  + Define some type synonyms:
    type Vec s a = a -> s    -- a for "axes", s for "scalars"
    type Mat s a b = b -> Vec s a  =  b -> (a -> s)
  + And helper functions:
    flip : (b -> a -> s) -> (a -> b -> s)
    flip op i j = op j i
    transpose : Mat s a b -> Mat s b a
    transpose m = \i j -> m j i
    getCol : Mat s a b -> a -> V s b
    getCol = flip
  + Also note a property of flip: (it is its own inverse)
      ∀ m. flip (flip m) == m
    or, equivalently,
      flip ∘ flip == id
+ How do we compute the matrix from a LinTran?
  Suppose we know
    h : A -> B; LinTran(h,A,B)
  but we want to find an m such that
    h = evalMV m
  Specification: the matrix should store the columns of h of the basis
    getCol m i == h (e i)
  = -- Def. of (∘), simplification
    getCol m == h ∘ e
  = -- Def. getCol = flip
    flip m == h ∘ e
  = -- Apply flip to both sides
    flip (flip m) == flip (h ∘ e)
  = -- flip is its own inverse
    m == flip (h ∘ e)
  Thus, we can get from h to the corresponding matrix and back
    m == flip (h ∘ e)
    h == evalMV m
  thus also the "round-trip property":
    m == flip (evalMV m ∘ e)
  which can be seen as a specification of evalMV.
+ Compute the matrix multiplication (in a similar way):
  Start from the setting above:
	 h₂      h₁
     C <———— B <———— A
         m₂      m₁

	    h₂∘h₁
     C <———————————— A
         mulM m₂ m₁
  where we know
    h₁ = evalMV m₁;
    h₂ = evalMV m₂;

  Start computing (towards a definition of mulM):
    getCol (mulM m₂ m₁) i
  = -- Specification of (mulM m₂ m₁)
    (h₂ ∘ h₁) eᵢ
  = -- Def. of (∘)
    h₂ (h₁ eᵢ)
  = -- Def. of h₂ and specification of m₁
    evalMV m₂ (getCol m₁ i)
  = -- Def. of (∘)
    (evalMV m₂ ∘ getCol m₁) i
  Thus we have
    getCol (mulM m₂ m₁) == evalMV m₂ ∘ getCol m₁
  and we can apply flip to both sides (as before)
    flip (getCol (mulM m₂ m₁)) == flip (evalMV m₂ ∘ getCol m₁)
  we notice  getCol = flip  and  flip ∘ flip = id
    mulM m₂ m₁ == flip (evalMV m₂ ∘ getCol m₁)
  This is now a definition of mulM which satisfies its specification.
  (Reminder: evalMV m v = linComb v m = Σᵢ scale vᵢ mᵢ)
+ Summing up:
  type A = Vec s a
  type B = Vec s b
  type C = Vec s c
  -- Notice that the b parameters makes sure the matrix dimensions match:
  mulM : Mat s a b -> Mat s b c -> Mat s a c
  mulM m₂ m₁ == flip (evalMV m₂ ∘ getCol m₁)

  evalMV = mulMV : Mat s a b -> Vec s a -> Vec s b

+ Perhaps some live-coding [[Live_7_1_2023.hs]]

** Lecture 7.2 / 8.1: Laplace Transforms
+ An application of linear algebra
+ ... and a method for solving ODEs
+ (Note: this transform is not implemented in Haskell in the course.)
*** [[https://jamboard.google.com/d/1n_fYYas1ahuNwJgm8TlcNJFA8KssNFqbQy4RGTRB95I/viewer?f=0][L8.1a]]
+ D (derivative) as a linear transform
+ Example: D exp = exp
+ g s t = exp (-s*t)
+ g s : V
+ Integral as a linear transform
+ "discovering" the Laplace transform
*** [[https://jamboard.google.com/d/1xaJLOHtVOI0zwkLRrXAiuSjpn3NpLfDjlTpHrigc6S0/viewer][L8.1b]]
+ Laplace transform examples: exp, sin, cos
+ Laplace for solving f''+2f=3f', f 0 = 0, f' 0 = 1
+ Laplace summary
